{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import numpy as np\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"./data\"\n",
    "epochs = ['średniowiecze', 'współczesność', 'modernizm', 'romantyzm', 'barok', 'oświecenie', 'renesans', 'pozytywizm', 'dwudziestolecie', 'starożytność']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'barok': 7520,\n",
       " 'data': 478860,\n",
       " 'dwudziestolecie': 30784,\n",
       " 'modernizm': 46736,\n",
       " 'nie': 1376,\n",
       " 'oświecenie': 11556,\n",
       " 'pozytywizm': 68124,\n",
       " 'renesans': 12992,\n",
       " 'romantyzm': 41012,\n",
       " 'starożytność': 4172,\n",
       " 'współczesność': 17560,\n",
       " 'średniowiecze': 1800}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sizes = ! du ./data\n",
    "epoch_sizes = {}\n",
    "for s in sizes:\n",
    "    size = s.split()[0]\n",
    "    name = s.split()[1].split('/')[-1]\n",
    "    epoch_sizes[name] = int(size)\n",
    "epoch_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'barok': 3,\n",
       " 'data': 11,\n",
       " 'dwudziestolecie': 6,\n",
       " 'modernizm': 7,\n",
       " 'nie': 0,\n",
       " 'oświecenie': 4,\n",
       " 'pozytywizm': 7,\n",
       " 'renesans': 4,\n",
       " 'romantyzm': 6,\n",
       " 'starożytność': 2,\n",
       " 'współczesność': 5,\n",
       " 'średniowiecze': 0}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = min(epoch_sizes.values())\n",
    "skips = 2*np.log(np.array(list(epoch_sizes.values())) / m)\n",
    "epoch_skips = {a: int(np.floor(b)) for a,b in zip(epoch_sizes.keys(),skips)}\n",
    "epoch_skips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " !\"'()*,-./0123456789:;<>?ABCDEFGHIJKLMNOPQRSTUVWXYZ[]abcdefghijklmnopqrstuvwxyz«­»ÓßàäèéêóöüĄąćčėĘęįŁłŃńŚśŠšūųŹźŻżž–—’”„…\n"
     ]
    }
   ],
   "source": [
    "!cd data; cat */*.txt > big_blob.txt\n",
    "with open('./data/big_blob.txt', 'r', encoding=\"utf-8\") as blob:\n",
    "    b = blob.read()\n",
    "    chars = set(b)\n",
    "    freq = {c: 0 for c in chars}\n",
    "    for c in list(b):\n",
    "        freq[c] +=1\n",
    "        \n",
    "    del b\n",
    "    \n",
    "freq_sorted = sorted(freq.items(), key=lambda x: x[1])\n",
    "freq_filtered = [x[0] for x in freq_sorted if x[1] > 1000]\n",
    "print(\"\".join(sorted(freq_filtered)))\n",
    "freq_filtered += [\"NULL\"]\n",
    "\n",
    "char_idx = {c: i for i, c in enumerate(sorted(freq_filtered))}\n",
    "pickle.dump(char_idx, open('charmap.pickle','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_text_with_epochs(files_dir, all_epochs, epoch, char_idx, epoch_skips, hdf_path =\"./dataset.h5f\", seq_maxlen=25, redun_step=3):\n",
    "    def map_char(char):\n",
    "        idx = char_idx.get(char)\n",
    "        if idx is None:\n",
    "            return char_idx['NULL']\n",
    "        else:\n",
    "            return idx\n",
    "        \n",
    "    len_chars = len(char_idx)\n",
    "    len_epochs = len(epochs)\n",
    "    vector_len = len_chars + len_epochs\n",
    "    \n",
    "    with h5py.File(hdf_path, \"a\") as hdf5_file:\n",
    "        Xt = hdf5_file.create_dataset('X', (0, seq_maxlen, vector_len), \n",
    "                                        maxshape=(None, seq_maxlen, vector_len),\n",
    "                                        dtype='bool')\n",
    "        \n",
    "        Yt = hdf5_file.create_dataset('Y', (0, len_chars), \n",
    "                                        maxshape=(None, len_chars),\n",
    "                                        dtype='bool')\n",
    "        \n",
    "\n",
    "\n",
    "        print(\"Processing: \",epoch, 'step=',redun_step+epoch_skips[epoch])\n",
    "        epoch_path = os.path.join(files_dir, epoch)\n",
    "        txt_files = [os.path.join(epoch_path, f) for f in os.listdir(epoch_path) if os.path.isfile(os.path.join(epoch_path, f))]\n",
    "\n",
    "        for file in tqdm(txt_files):\n",
    "            with open(file, 'rt') as txt:\n",
    "                string = txt.read()\n",
    "                string = string[:-1236] #removing footnote\n",
    "\n",
    "                sequences = []\n",
    "                next_chars = []\n",
    "                step = redun_step + epoch_skips[epoch]\n",
    "                for i in range(0, len(string) - seq_maxlen, redun_step):\n",
    "                    sequences.append(string[i: i + seq_maxlen])\n",
    "                    next_chars.append(string[i + seq_maxlen])\n",
    "\n",
    "                x = np.zeros((len(sequences), seq_maxlen, vector_len), dtype=np.bool)\n",
    "                y = np.zeros((len(sequences), len_chars), dtype=np.bool)\n",
    "                for i, seq in enumerate(sequences):\n",
    "                    for t, char in enumerate(seq):\n",
    "                        x[i, t, map_char(char)] = 1\n",
    "                        x[i, t, len_chars + epochs.index(epoch)] = 1\n",
    "                    y[i, map_char(next_chars[i])] = 1\n",
    "\n",
    "                x_len = x.shape[0]\n",
    "                Xt.resize(Xt.shape[0]+x_len, axis=0)   \n",
    "                Xt[-x_len:] = x\n",
    "\n",
    "                y_len = y.shape[0]\n",
    "                Yt.resize(Yt.shape[0]+y_len, axis=0)   \n",
    "                Yt[-y_len:] = y\n",
    "                \n",
    "        shapes = (Xt.shape, Yt.shape)\n",
    "        print(shapes)\n",
    "                \n",
    "    return shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing:  średniowiecze step= 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:19<00:00,  1.95s/it]\n"
     ]
    }
   ],
   "source": [
    "#shapes = process_text_with_epochs(data_dir, epochs, 'średniowiecze', char_idx, epoch_skips)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((550534, 25, 134), (550534, 124))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing:  współczesność step= 8\n",
      "Processing:  romantyzm step= 9\n",
      "Processing:  barok step= 6\n",
      "Processing:  renesans step= 7\n",
      "Processing:  nie step= 3\n",
      "Processing:  średniowiecze step= 3\n",
      "Processing:  oświecenie step= 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing:  modernizm step= 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 16/830 [00:06<05:52,  2.31it/s]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Process ForkPoolWorker-11:\n",
      "Process ForkPoolWorker-14:\n",
      "Process ForkPoolWorker-15:\n",
      "Process ForkPoolWorker-12:\n",
      "Process ForkPoolWorker-9:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 119, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 119, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 119, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-15-b9ecf74a5d8e>\", line 43, in process_text_with_epochs\n",
      "    x[i, t, map_char(char)] = 1\n",
      "  File \"<ipython-input-15-b9ecf74a5d8e>\", line 44, in process_text_with_epochs\n",
      "    x[i, t, len_chars + epochs.index(epoch)] = 1\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 119, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"<ipython-input-15-b9ecf74a5d8e>\", line 3, in map_char\n",
      "    idx = char_idx.get(char)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 119, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"<ipython-input-15-b9ecf74a5d8e>\", line 44, in process_text_with_epochs\n",
      "    x[i, t, len_chars + epochs.index(epoch)] = 1\n",
      "  File \"<ipython-input-15-b9ecf74a5d8e>\", line 44, in process_text_with_epochs\n",
      "    x[i, t, len_chars + epochs.index(epoch)] = 1\n",
      "  File \"<ipython-input-15-b9ecf74a5d8e>\", line 44, in process_text_with_epochs\n",
      "    x[i, t, len_chars + epochs.index(epoch)] = 1\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "\n",
      "Process ForkPoolWorker-16:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 119, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"<ipython-input-15-b9ecf74a5d8e>\", line 49, in process_text_with_epochs\n",
      "    Xt[-x_len:] = x\n",
      "  File \"h5py/_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py/_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper\n",
      "  File \"/home/dreamage/badania/phdopen_lm/venv/lib/python3.5/site-packages/h5py/_hl/dataset.py\", line 632, in __setitem__\n",
      "    self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)\n",
      "KeyboardInterrupt\n",
      "Process ForkPoolWorker-10:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 119, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "\n",
      "  File \"<ipython-input-15-b9ecf74a5d8e>\", line 43, in process_text_with_epochs\n",
      "    x[i, t, map_char(char)] = 1\n",
      "KeyboardInterrupt\n",
      "Process ForkPoolWorker-13:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 119, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"<ipython-input-15-b9ecf74a5d8e>\", line 49, in process_text_with_epochs\n",
      "    Xt[-x_len:] = x\n",
      "  File \"h5py/_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py/_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper\n",
      "  File \"/home/dreamage/badania/phdopen_lm/venv/lib/python3.5/site-packages/h5py/_hl/dataset.py\", line 632, in __setitem__\n",
      "    self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing import Pool\n",
    "pool = Pool()\n",
    "\n",
    "for epoch in epochs:\n",
    "    pool.apply_async(process_text_with_epochs, [data_dir, epochs, epoch, \n",
    "                                                char_idx, epoch_skips,\n",
    "                                                \"dataset_\"+epoch+\".h5f\",\n",
    "                                                25, 3])\n",
    "    \n",
    "pool.close()\n",
    "pool.join()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
